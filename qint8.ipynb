{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from occupancy.pipelines.autoencoderkl_3d import AutoEncoderKL3d, AutoEncoderKL3dConfig\n",
    "import torch\n",
    "import math\n",
    "import logging\n",
    "from torch import nn, Tensor, onnx\n",
    "vae3d = AutoEncoderKL3d(1, 1, 16, exportable=True)\n",
    "vae3d.load_state_dict(torch.load('/home/zc2309/workspace/occupancy/models/autoencoderkl-cls1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.097152"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 * 256 * 32 / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occ_shuffle(occ: t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "tensor_x = torch.rand(1, 1, 256, 256, 32).float()\n",
    "tensor_y = torch.rand(1, 16, 32, 32, 4).float()\n",
    "vae3d = vae3d.float()\n",
    "encoder_onnx = onnx.dynamo_export(vae3d.encoder, tensor_x)\n",
    "decoder_onnx = onnx.dynamo_export(vae3d.decoder, tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_onnx.save('autoencoderkl-cls1-encoder.onnx')\n",
    "decoder_onnx.save('autoencoderkl-cls1-decoder.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32 * 32 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserizba/salad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdinov2_salad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "torch.hub.load('serizba/salad', 'dinov2_salad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "conv= nn.Conv2d(3, 6,1)\n",
    "y = conv(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zc2309/mambaforge/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, hidden_size: int, patch_size: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.positional_embeds = nn.Embedding(100000, hidden_size)\n",
    "        self.register_buffer(\"positional_ids\", torch.arange(100000).unsqueeze(0))\n",
    "        self.patch_conv = nn.Conv2d(in_channels, hidden_size, patch_size, stride=patch_size)\n",
    "        self.patch_deconv = nn.ConvTranspose2d(hidden_size, out_channels, patch_size, stride=patch_size)\n",
    "        self.model = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                hidden_size,\n",
    "                hidden_size // 64,\n",
    "                hidden_size * 8 // 3,\n",
    "                activation=F.silu,\n",
    "                batch_first=True,\n",
    "                norm_first=True,\n",
    "            ),\n",
    "            num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        hidden = self.patch_conv(x)\n",
    "        n_seq = hidden.shape[2] * hidden.shape[3]\n",
    "        pos_embeds = self.positional_embeds(self.positional_ids[:, :n_seq]).expand(hidden.shape[0], -1, -1)\n",
    "        output = self.model(hidden.flatten(2).transpose(1, 2) + pos_embeds).transpose(-1, -2).view_as(hidden)\n",
    "        output = self.patch_deconv(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "vit = VisionTransformer(3, 3, 512, 4, 12)\n",
    "x = torch.randn(1, 3, 256, 256)\n",
    "y = vit(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "from torchvision import models  # type: ignore\n",
    "from torchvision.models.feature_extraction import (  # type: ignore\n",
    "    create_feature_extractor,\n",
    ")\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_dim: int,\n",
    "        hidden_size: int,\n",
    "        patch_size: int,\n",
    "        num_layers: int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = models.vit_l_16(\n",
    "            weights=models.ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1\n",
    "        )\n",
    "        self.encoder.requires_grad_(False)\n",
    "        for i in range(8):\n",
    "            self.encoder.encoder.layers[-i].requires_grad_(True)\n",
    "        self.encoder = create_feature_extractor(\n",
    "            self.encoder, {\"encoder.layers.encoder_layer_23.add_1\": \"encoder_output\"}\n",
    "        )\n",
    "        self.pre_avg_proj = nn.Linear(hidden_size, feat_dim)\n",
    "        self.out_norm = nn.InstanceNorm1d(feat_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.encoder(x)[\"encoder_output\"]\n",
    "        x = self.pre_avg_proj(x)\n",
    "        x = x.mean(dim=-2)\n",
    "        x = self.out_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8067a2ca6d8d42f9bd0b383476868059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d343918a65a4c2a9efa60d59dc0d0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_minicpm.py:   0%|          | 0.00/9.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16:\n",
      "- configuration_minicpm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4186908440444d67b0542f079dc7847c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_minicpm.py:   0%|          | 0.00/67.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16:\n",
      "- modeling_minicpm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550fa46230274e93b8100f73bf4bb8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0efdfd8f7dc4a09925b45b6640758da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openbmb/MiniCPM-2B-dpo-bf16\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "山东省最高的山是泰山，海拔1545米。而黄山位于中国安徽省，海拔1864米。因此，泰山比黄山矮，相差319米。\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "path = 'openbmb/MiniCPM-2B-dpo-bf16'\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map='cuda', trust_remote_code=True)\n",
    "\n",
    "responds, history = model.chat(tokenizer, \"山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？如果你需要查资料验证，随时可以告诉我。\", temperature=0.8, top_p=0.8)\n",
    "print(responds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c98fb96bcb147c49bd100e1f983ea2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=torch.bfloat16, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instruct: Please translate this from English to Chinese: \"Hello, how are you?\"\n",
      "Output: \n",
      "你好，你怎么样？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"\"\"\n",
    "Instruct: Please translate this from English to Chinese: \"Hello, how are you?\"\n",
    "Output: \n",
    "\"\"\"\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "output = model.generate(input_ids, do_sample=True, max_length=50, num_return_sequences=3, temperature=0.7)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
